# 少犯错：AI 时代的第一性原理思维

> "多做正确的事"反过来就是"少犯错"。

## 序言

你每天会做出多少个决定？也许没意识到，但这个数字可能是几百甚至上千。在做这些决定时，我们当然希望多做正确的事。然而世界错综复杂，往往很难一直做正确的事——你常常会遇到陌生的情况，面对众多选项，即使找到正确答案，往往也是事后才恍然大悟。

怎么办？

答案是：**少犯错**。

---

## 逆向思维：少犯错的起点

> "多做正确的事" ↔ **"少犯错"**

这个简单的转换，就是逆向思维（Inverse Thinking）。

在网球比赛中，有一种失误叫"主动失误"（Unforced Error）——不是因为对手打得好，而是因为自己判断出错或执行力差导致的失误。减少主动失误，就是减少犯错。

生活中的"主动失误"有哪些？

| 失误类型 | 描述 | 示例 |
|---------|------|------|
| **主动失误** | 自己判断/执行出错 | 轻易能做的事却搞砸 |
| **非主动失误** | 外部压力导致 | 时间紧迫、突发干扰 |
| **描述性失误** | 沟通不精确导致混淆 | 需求没说清 |
| **数据干扰失误** | 突发刺激干扰 | 考试时有人说话 |
| **忘记目的失误** | 忘记原本要做什么 | 开会忘了要讨论什么 |

---

## 第一性原理：少犯错的思维方式

### 什么是第一性原理？

第一性原理（First Principles）指的是自下而上地思考问题，运用你认为是正确的基本构件，得出合理的、有时是全新的结论。

它就像几何学中的公理——不需要证明、无法证明的几条基本假设。欧几里得几何学的五条公理，构成了整个几何学大厦的基础。

**类比思维 vs 第一性原理：**

- **类比思维**：记住定理 100，反复套用。定理失效就抓瞎。
- **第一性原理**：不仅知道定理 100，更清楚它由哪几条公理推导出来。环境变了，能迅速推导出定理 101。

### 一个经典例子

MIT 统计学课程考试，一名学生答题："我会用磁盘，输入数字，得出答案。"

显然，他不是真正的"大厨"。

在《厨艺大战》中，指定若干食材，**大厨**能运用自如创造新菜，而**厨子**只能按流程做完。

> 那个依赖磁盘算统计题的学生，和今天遇到问题只会说"我去问问 AI"的人，本质上犯了同一个逻辑错误。

---

## AI 时代的第一性原理

### 为什么依赖 AI 不是第一性原理？

当你遇到难题直接丢给 AI 并照搬答案时，你使用的是"类比思维"（思维外包）。AI 的底层逻辑（大语言模型）本身就是基于海量历史数据进行概率预测的"经验主义"。

你只是**咀嚼别人嚼过的东西**。

### AI 时代的两种人

未来世界会残酷地分为两类人：

| 类型 | 特征 | 结局 |
|------|------|------|
| **被 AI 驯化的生物 API** | 遇事只问 AI，执行 AI 指令 | 随时可被替换 |
| **掌握第一性原理的超级大厨** | 深刻理解本质，把 AI 当工具 | 创造前所未有的"新菜" |

### 正确的姿势

```
我能徒手起大厦：剥离所有工具，我依然知道底层逻辑
         ↓
我用工具提效率：既然懂了原理，让 AI 帮我快速生成框架
         ↓
我具备批判性纠错能力：当 AI 偏离时，我能敏锐指出错在哪
```

---

## 回到现实：去风险化

即使从第一性原理出发，你也可能犯错。

第一性原理仅仅是**假设**，可能是对的，也可能是错的。你真的在乎工作中的自主权吗？还是只是"认为"自己在乎？

**最后一步：去风险化（De-risking）**

在现实世界中测试假设，验证结论是否成立。

---

## 总结

1. **逆向思维**：把"多做正确的事"变成"少犯错"
2. **第一性原理**：从最基本的假设出发，不依赖经验
3. **AI 时代**：不要让 AI 代替你思考，让 AI 替你检索、和你 debate
4. **去风险化**：用现实测试假设，验证结论

> 世界很残酷 要么被 AI 驯化，要么成为超级大厨

---

*本文整理自阅读笔记*
